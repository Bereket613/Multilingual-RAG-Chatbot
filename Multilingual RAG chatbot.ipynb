{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKmfLknrshWH",
        "outputId": "e303c162-6569-4507-ac2c-c81f068d5813"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.1)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.8.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.11/dist-packages (1.0.9)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.31.0)\n",
            "Requirement already satisfied: wikipedia in /usr/local/lib/python3.11/dist-packages (1.4.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.11.0)\n",
            "Requirement already satisfied: PyMuPDF in /usr/local/lib/python3.11/dist-packages (1.26.3)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: gtts in /usr/local/lib/python3.11/dist-packages (2.5.4)\n",
            "Requirement already satisfied: tokenizer in /usr/local/lib/python3.11/dist-packages (3.4.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from langdetect) (1.17.0)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.14)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.6.0)\n",
            "Requirement already satisfied: gradio-client==1.10.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.10.1)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.18)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.2.1)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.7)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.12.2)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.46.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.14.1)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.35.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (15.0.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from wikipedia) (4.13.4)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.11/dist-packages (from gtts) (8.1.8)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.6.15)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->wikipedia) (2.7)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers accelerate sentencepiece langdetect gradio wikipedia datasets faiss-cpu PyMuPDF torchaudio gtts tokenizer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "V9-usjGtu_Bh"
      },
      "outputs": [],
      "source": [
        "# ---- IMPORTS ----\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
        "from langdetect import detect\n",
        "import gradio as gr\n",
        "import wikipedia\n",
        "import torch\n",
        "import os\n",
        "import fitz  # PyMuPDF\n",
        "import faiss\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from gtts import gTTS\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvR429j2vuCJ",
        "outputId": "3337f13e-bc5c-4b30-dd9c-722aef19c112"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
            "  warnings.warn(\"Recommended: pip install sacremoses.\")\n",
            "Device set to use cpu\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
            "  warnings.warn(\"Recommended: pip install sacremoses.\")\n",
            "Device set to use cpu\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
            "  warnings.warn(\"Recommended: pip install sacremoses.\")\n",
            "Device set to use cpu\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
            "  warnings.warn(\"Recommended: pip install sacremoses.\")\n",
            "Device set to use cpu\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
            "  warnings.warn(\"Recommended: pip install sacremoses.\")\n",
            "Device set to use cpu\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
            "  warnings.warn(\"Recommended: pip install sacremoses.\")\n",
            "Device set to use cpu\n"
          ]
        }
      ],
      "source": [
        "# ---- TRANSLATION PIPELINES ----\n",
        "# English to others\n",
        "en_to_fr = pipeline(\"translation\", model=\"Helsinki-Nlp/opus-mt-en-fr\")\n",
        "en_to_ar = pipeline(\"translation\", model=\"Helsinki-Nlp/opus-mt-en-ar\")\n",
        "en_to_es = pipeline(\"translation\", model=\"Helsinki-Nlp/opus-mt-en-es\")\n",
        "\n",
        "# Others to English\n",
        "fr_to_en = pipeline(\"translation\", model=\"Helsinki-Nlp/opus-mt-fr-en\")\n",
        "ar_to_en = pipeline(\"translation\", model=\"Helsinki-Nlp/opus-mt-ar-en\")\n",
        "es_to_en = pipeline(\"translation\", model=\"Helsinki-Nlp/opus-mt-es-en\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CF6c15TlvuIY",
        "outputId": "d451a7f7-2723-45ee-d8e7-44e922a6e505"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cpu\n",
            "Device set to use cpu\n"
          ]
        }
      ],
      "source": [
        "model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
        "\n",
        "llm_tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "llm_model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "llm_pipeline = pipeline(\"text-generation\", model=llm_model, tokenizer=llm_tokenizer)\n",
        "# ---- WHISPER FOR SPEECH INPUT ----\n",
        "asr = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-base\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "0g2B2j156YJJ"
      },
      "outputs": [],
      "source": [
        "# ---- TRANSLATION HELPERS ----\n",
        "def translate_to_en(text):\n",
        "    lang = detect(text)\n",
        "    if lang == \"fr\":\n",
        "        return fr_to_en(text)[0]['translation_text'], lang\n",
        "    elif lang == \"ar\":\n",
        "        return ar_to_en(text)[0]['translation_text'], lang\n",
        "    elif lang == \"es\":\n",
        "        return es_to_en(text)[0]['translation_text'], lang\n",
        "    return text, \"en\"\n",
        "\n",
        "def translate_from_en(text, target_lang):\n",
        "    if target_lang == \"fr\":\n",
        "        return en_to_fr(text)[0]['translation_text']\n",
        "    elif target_lang == \"ar\":\n",
        "        return en_to_ar(text)[0]['translation_text']\n",
        "    elif target_lang == \"es\":\n",
        "        return en_to_es(text)[0]['translation_text']\n",
        "    return text\n",
        "\n",
        "# ---- AUDIO ----\n",
        "def transcribe_audio(file):\n",
        "    return asr(file)[\"text\"]\n",
        "\n",
        "def synthesize_speech(text, lang_code=\"en\"):\n",
        "    tts = gTTS(text, lang=lang_code)\n",
        "    file_path = \"output.mp3\"\n",
        "    tts.save(file_path)\n",
        "    return file_path\n",
        "\n",
        "# ---- WIKIPEDIA RAG ----\n",
        "def get_wikipedia_context(topic):\n",
        "    try:\n",
        "        page = wikipedia.page(topic)\n",
        "        return page.content[:3000]\n",
        "    except:\n",
        "        return f\"Could not retrieve content for '{topic}'. Try another topic.\"\n",
        "\n",
        "def generate_final_answer(question, topic, lang):\n",
        "    input_en, detected = translate_to_en(question)\n",
        "    context = get_wikipedia_context(topic)\n",
        "\n",
        "    prompt = f\"\"\"You are a helpful assistant. Use the following Wikipedia context to answer the question clearly and correctly.\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question:\n",
        "{input_en}\n",
        "\n",
        "Answer:\"\"\"\n",
        "    raw_output = llm_pipeline(prompt, max_new_tokens=200)[0]['generated_text']\n",
        "    answer = raw_output.split(\"Answer:\")[-1].strip()\n",
        "    return translate_from_en(answer, lang)\n",
        "\n",
        "# ---- PDF MODE ----\n",
        "def extract_text_from_pdf(file_path):\n",
        "    with open(file_path, \"rb\") as f:\n",
        "        pdf_bytes = f.read()\n",
        "    doc = fitz.open(stream=pdf_bytes, filetype=\"pdf\")\n",
        "    return \"\\n\".join(page.get_text() for page in doc)\n",
        "\n",
        "def split_chunks(text, chunk_size=100, overlap=20):\n",
        "    words = text.split()\n",
        "    return [' '.join(words[i:i+chunk_size]) for i in range(0, len(words), chunk_size - overlap)]\n",
        "\n",
        "def build_faiss_index(chunks):\n",
        "    vectorizer = TfidfVectorizer().fit(chunks)\n",
        "    vectors = vectorizer.transform(chunks).toarray().astype('float32')\n",
        "    index = faiss.IndexFlatL2(vectors.shape[1])\n",
        "    index.add(vectors)\n",
        "    return index, vectorizer, chunks\n",
        "\n",
        "def search_chunks(question, index, vectorizer, chunks, k=3):\n",
        "    q_vec = vectorizer.transform([question]).toarray().astype('float32')\n",
        "    _, indices = index.search(q_vec, k)\n",
        "    return \"\\n\".join([chunks[i] for i in indices[0] if i < len(chunks)])\n",
        "\n",
        "def ask_from_pdf(pdf_file, question, lang):\n",
        "    try:\n",
        "        text = extract_text_from_pdf(pdf_file)\n",
        "        chunks = split_chunks(text)\n",
        "        index, vectorizer, chunks = build_faiss_index(chunks)\n",
        "        relevant = search_chunks(question, index, vectorizer, chunks)\n",
        "\n",
        "        translated_question, _ = translate_to_en(question)\n",
        "        prompt = f\"\"\"You are a helpful assistant. Use the following document context to answer the question clearly.\n",
        "\n",
        "Context:\n",
        "{relevant}\n",
        "\n",
        "Question:\n",
        "{translated_question}\n",
        "\n",
        "Answer:\"\"\"\n",
        "        generated = llm_pipeline(prompt, max_new_tokens=200)[0]['generated_text']\n",
        "        answer = generated.split(\"Answer:\")[-1].strip()\n",
        "        return translate_from_en(answer, lang)\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\"\n",
        "\n",
        "        # ---- WEBSITE MODE ----\n",
        "\n",
        "def get_text_from_url(url):\n",
        "    try:\n",
        "        response = requests.get(url, timeout=10)\n",
        "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "        # Remove script and style tags\n",
        "        for tag in soup([\"script\", \"style\"]):\n",
        "            tag.extract()\n",
        "\n",
        "        text = soup.get_text(separator=' ')\n",
        "        return ' '.join(text.split())[:10000]  # Limit to 10k chars\n",
        "    except Exception as e:\n",
        "        return f\"Failed to fetch content from {url}: {e}\"\n",
        "\n",
        "def ask_from_website(url, question, lang):\n",
        "    website_text = get_text_from_url(url)\n",
        "    chunks = split_chunks(website_text)\n",
        "    index, vectorizer, chunk_list = build_faiss_index(chunks)\n",
        "    relevant = search_chunks(question, index, vectorizer, chunk_list)\n",
        "\n",
        "    translated_question, _ = translate_to_en(question)\n",
        "    prompt = f\"\"\"You are a helpful assistant. Use the following website content to answer the question clearly.\n",
        "\n",
        "Website Content:\n",
        "{relevant}\n",
        "\n",
        "Question:\n",
        "{translated_question}\n",
        "\n",
        "Answer:\"\"\"\n",
        "\n",
        "    result = llm_pipeline(prompt, max_new_tokens=200)[0]['generated_text']\n",
        "    answer = result.split(\"Answer:\")[-1].strip()\n",
        "    return translate_from_en(answer, lang)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "B1V-hNd_8AqW",
        "outputId": "bd337f72-fdf8-42e7-a620-8d3e5a230eb7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://320a71904efede6bcf.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://320a71904efede6bcf.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ---- INTERFACES ----\n",
        "def chatbot_interface(question, topic, target_lang):\n",
        "    return generate_final_answer(question, topic, target_lang)\n",
        "\n",
        "def voice_to_voice_chat(audio_input, topic, target_lang):\n",
        "    question_text = transcribe_audio(audio_input)\n",
        "    answer_text = generate_final_answer(question_text, topic, target_lang)\n",
        "    audio_output = synthesize_speech(answer_text, lang_code=target_lang)\n",
        "    return question_text, answer_text, audio_output\n",
        "\n",
        "# ---- GRADIO UI ----\n",
        "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
        "    gr.Markdown(\"##  Multilingual RAG Chatbot with TinyLlama\")\n",
        "    gr.Markdown(\"Ask your question by typing, speaking, or uploading a PDF.\\\\nSupports English, French, Arabic, and Spanish.\")\n",
        "\n",
        "    with gr.Tabs():\n",
        "        with gr.TabItem(\"Text Mode\"):\n",
        "            topic = gr.Textbox(label=\"Topic\")\n",
        "            question = gr.Textbox(label=\"Your Question\")\n",
        "            lang = gr.Dropdown([\"en\", \"fr\", \"ar\", \"es\"], label=\"Output Language\", value=\"en\")\n",
        "            output = gr.Markdown()\n",
        "            gr.Button(\"Get Answer\").click(fn=chatbot_interface, inputs=[question, topic, lang], outputs=output)\n",
        "\n",
        "        with gr.TabItem(\"Voice Mode\"):\n",
        "            topic_voice = gr.Textbox(label=\"Topic\")\n",
        "            lang_voice = gr.Dropdown([\"en\", \"fr\", \"ar\", \"es\"], label=\"Output Language\", value=\"en\")\n",
        "            audio_in = gr.Audio(type=\"filepath\", label=\"Speak your question\")\n",
        "            transcript = gr.Textbox(label=\"Transcribed\")\n",
        "            answer = gr.Textbox(label=\"Answer\")\n",
        "            audio_out = gr.Audio(label=\"Spoken Answer\")\n",
        "            gr.Button(\"Get Spoken Answer\").click(fn=voice_to_voice_chat, inputs=[audio_in, topic_voice, lang_voice],\n",
        "                                                 outputs=[transcript, answer, audio_out])\n",
        "\n",
        "        with gr.TabItem(\"Document Upload\"):\n",
        "            pdf_file = gr.File(label=\"Upload PDF\", file_types=[\".pdf\"])\n",
        "            pdf_question = gr.Textbox(label=\"Ask a question from the PDF\")\n",
        "            pdf_lang = gr.Dropdown([\"en\", \"fr\", \"ar\", \"es\"], value=\"en\", label=\"Output Language\")\n",
        "            pdf_answer = gr.Textbox(label=\"Answer\")\n",
        "            gr.Button(\"Ask from PDF\").click(fn=ask_from_pdf, inputs=[pdf_file, pdf_question, pdf_lang], outputs=pdf_answer)\n",
        "\n",
        "        with gr.TabItem(\"Website Mode\"):\n",
        "            url_input = gr.Textbox(label=\"Website URL\")\n",
        "            web_question = gr.Textbox(label=\"Ask a question from the website\")\n",
        "            web_lang = gr.Dropdown([\"en\", \"fr\", \"ar\", \"es\"], value=\"en\", label=\"Output Language\")\n",
        "            web_answer = gr.Textbox(label=\"Answer\")\n",
        "            gr.Button(\"Ask from Website\").click(fn=ask_from_website,inputs=[url_input, web_question, web_lang],outputs=web_answer)\n",
        "\n",
        "\n",
        "demo.launch()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
